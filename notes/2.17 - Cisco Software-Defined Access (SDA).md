# Cisco Software-Defined Access (SDA)
## SDA Fabric, Underlay, and Overlay
SDA uses the software-defined architectural model with a controller and various APIs. It still uses a physical network with switches and routers, cables, and various endpoints. At the center sits the Digital Network Architecture (DNA) Center controller with human users making use of a GUI) and automation using APIs. DNA Center is the controller for SDA networks.

Architecturally, the southbound side of the controller contains the fabric, underlay, and overlay. By design in SDN implementations, most of the interesting new capabilities occur on the northbound side.

- <b>Overlay</b>: The mechanisms to create VXLAN tunnels between SDA switches, which are then used to transport traffic from one fabric endpoint to another over the fabric. 
- <b>Underlay</b>: The network of devices and connections (cables and wireless) to provide IP connectivity to all nodes in the fabric, with a goal to support the dynamic discovery of all SDA devices and endpoints as a part of the process to create overlay VXLAN tunnels. 
- <b>Fabric</b>: The combination of overlay and underlay, which together provide all features to deliver data across the network with the desired features and attributes.

The underlay exists as multilayer switches and their links, with IP connectivity—but for a special purpose. The underlay supports some new concepts with a tunneling method called VXLAN. Traffic sent by the endpoint devices flows through VXLAN tunnels in the overlay—a completely different process than traditional LAN switching and IP routing.

Fabric edge nodes are the switches that happen to be at the edges of the SDA fabric—with a tunnel labeled VXLAN connecting the two. Both concepts (underlay and overlay) together create the SDA fabric.

### The SDA Underlay
To build an SDA underlay network , companies have two basic choices:
- use their existing campus network and add new configuration to create an underlay network, while still supporting their existing production traffic with traditional routing and switching. 
- purchase some new switches and build the SDA network without concern for harming existing traffic, and migrate endpoints to the new SDA network over time.

Some issues with SDA migration on an existing network :
- Because of the possibility of harming the existing production configuration, DNA Center should not be used to configure the underlay if the devices are currently used in production. (DNA Center will be used to configure the underlay with deployments that use all new hardware.)
- The existing hardware must be from the SDA compatibility list, with different models supported depending on their different SDA roles 
- The device software levels must meet the requirements, based on their roles, as detailed in that same compatibility list.

Different lists of supported hardware and software depending on the roles. These roles include :
- <b>Fabric edge node</b>: A switch that connects to endpoint devices (similar to traditional access switches) 
- <b>Fabric border node</b>: A switch that connects to devices outside SDA’s control, for example, switches that connect to the WAN routers or to an ACI data center 
- <b>Fabric control node</b>: A switch that performs special control plane functions for the underlay (LISP), requiring more CPU and memory

#### Using New Gear for the SDA Underlay
Buying new hardware for the SDA fabric, called a greenfield design, DNA Center can configure all the underlay features automatically.

The usual campus LAN design decisions still need to be made. Enterprises use SDA as a better way to build and operate a campus network, but SDA is still a campus network. It needs to provide access and connectivity to all types of user devices. 

When planning a greenfield SDA design, plan to use SDA-compatible hardware, but also:
- The number of ports needed in switches in each wiring closet 
- The port speeds required 
- The benefit of a switch stack in each wiring closet 
- The cable length and types of cabling already installed 
- The need for power (PoE/PoE+) 
- The power available in each new switch versus the PoE power requirements
- Link capacity (speed and number of links) for links between switches

A greenfield SDA fabric uses a routed access layer design. A routed access layer design simply means that all the LAN switches are Layer 3 switches, with routing enabled, so all the links between switches operate as Layer 3 links. DNA Center will configure the devices’ underlay configuration to use a routed access layer. 

The best configuration happens to use a design called a routed access layer design, which has these features: 
- All switches act as Layer 3 switches. 
- The switches use the IS-IS routing protocol. 
- All links between switches (single links, EtherChannels) are routed Layer 3 links (not Layer 2 links).
- As a result, STP/RSTP is not needed, with the routing protocol instead choosing which links to use based on the IP routing tables.
- The equivalent of a traditional access layer switch—an SDA edge node—acts as the default gateway for the endpoint devices, rather than distribution switches.
- As a result, HSRP (or any FHRP) is no longer needed.

### The SDA Overlay
he first SDA node to receive the frame encapsulates the frame in a new message—using a tunneling specification called VXLAN—and forwards the frame into the fabric. Once the ingress node has encapsulated the original frame in VXLAN, the other SDA nodes forward the frame based on the VXLAN tunnel details. 

All that work happens in each switch’s ASIC. So, while it is more complex to understand, there is no performance penalty.

#### VXLAN Tunnels in the Overlay (Data Plane)

SDA does not only route IP packets or switch Ethernet frames. Instead, it encapsulates incoming data link frames in a tunneling technology for delivery across the SDA network, with these goals in mind:
- The VXLAN tunneling (the encapsulation and de-encapsulation) must be performed by the ASIC on each switch so that there is no performance penalty. (That is one reason for the SDA hardware compatibility list: the switches must have ASICs that can perform the work.)
- The VXLAN encapsulation must supply header fields that SDA needs for its features, so the tunneling protocol should be flexible and extensible, while still being supported by the switch ASICs.
- The tunneling encapsulation needs to encapsulate the entire data link frame instead of encapsulating the IP packet. That allows SDA to support Layer 2 forwarding features as well as Layer 3 forwarding features.

Virtual Extensible LAN (VXLAN) protocol to create the tunnels used by SDA.

To support the VXLAN encapsulation, the underlay uses a separate IP address space as compared with the rest of the enterprise, including the endpoint devices that send data over the SDA network. The overlay tunnels use addresses from the enterprise address space. 

The overlay tunnel creates a path between two fabric edge nodes in the overlay IP address space—that is, in the same address space used by all the endpoints in the enterprise.

#### LISP for Overlay Discovery and Location (Control Plane)

- Traditional Layer 2 switches learn possible destinations by examining the source MAC addresses of incoming frames, storing those MAC addresses as possible future destinations in the switch’s MAC address table. When new frames arrive, the Layer 2 switch data plane then attempts to match the Ethernet frame’s destination MAC address to an entry in its MAC address table.
-  Traditional Layer 3 routers learn destination IP subnets using routing protocols, storing routes to reach each subnet in their routing tables. When new packets arrive, the Layer 3 data plane attempts to match the IP packet’s destination IP address to some entry in the IP routing table.


Nodes in the SDA network do not do these same control plane actions to support endpoint traffic :
- Fabric edge nodes—SDA nodes that connect to the edge of the SDA fabric—learn the location of possible endpoints using traditional means, based on their MAC address, individual IP address, and by subnet, identifying each endpoint with an endpoint identifier (EID).
- The fabric edge nodes register the fact that the node can reach a given endpoint (EID) into a database called the LISP map server.
- The LISP map server keeps the list of endpoint identifiers (EIDs) and matching routing locators (RLOCs) (which identify the fabric edge node that can reach the EID).
- In the future, when the fabric data plane needs to forward a message, it will look for and
find the destination in the LISP map server’s database.

    ! Check the examples on the book. 

## DNA Center and SDA Operation
Cisco DNA Center (www.cisco.com/go/dnacenter) has two notable roles: 
- As the controller in a network that uses Cisco SDA
- As a network management platform for traditional (non-SDA) network devices, with an expectation that one day DNA Center may become Cisco’s primary enterprise network management platform

### Cisco DNA Center
Cisco DNA Center exists as a software application that Cisco delivers pre-installed on a Cisco DNA Center appliance.
DNA Center includes a robust northbound REST API along with a series of southbound APIs.

Cisco DNA Center supports several southbound APIs so that the controller can communicate with the devices it manages. You can think of these as two categories:
- Protocols to support traditional networking devices/software versions: Telnet, SSH, SNMP
- Protocols to support more recent networking devices/software versions: NETCONF, RESTCONF

### Cisco DNA Center and Scalable Groups
#### Issues with Traditional IP-Based Security
ACL management suffers with these kinds of issues : 
- ACEs cannot be removed from ACLs because of the risk of causing failures to the logic for some other past requirement.
- New changes become more and more challenging due to the length of the ACLs. 
- Troubleshooting ACLs as a system—determining whether a packet would be delivered from end-to-end—becomes an even greater challenge.

#### SDA Security Based on User Groups
Enforce security without even thinking about IP address ranges.

Intent-based networking (IBN) : The engineer configures the intent or outcome desired from the network—in this case, a set of security policies. The controller communicates with the devices in the network, with the devices determining exactly what configuration and behavior are necessary to achieve those intended policies.

The engineer can consider each new security requirement separately, without analysis of an existing (possibly lengthy) ACL.
- Each new requirement can be considered without searching for all the ACLs in the likely paths between endpoints and analyzing each and every ACL .
- DNA Center (and related software) keeps the policies separate, with space to keep notes about the reason for the policy.
- Each policy can be removed without fear of impacting the logic of the other policies.

SDA and Cisco DNA achieve this particular feature by tying security to groups of users, called scalable groups, with each group assigned a scalable group tag (SGT). Then the engineer configures a grid that identifies which SGTs can send packets to which other SGTs.

When a new endpoint tries to send its first packet to a new destination the ingress SDA node starts a process by sending messages to DNA Center. DNA Center then works with security tools in the network, like Cisco’s Identity Services Engine (ISE), to identify the users and then match them to their respective SGTs. DNA Center then checks the logic. If DNA Center sees a permit action between the source/destination pair of SGTs, DNA Center directs the edge nodes to create the VXLAN tunnel. If the security policies state that the two SGTs should not be allowed to communicate, DNA Center does not direct the fabric to create the tunnel, and the packets do not flow.

    SDA goes to the trouble of using VXLAN encapsulation for its data plane, rather than performing traditional Layer 2 switching or Layer 3 routing. The VXLAN header has great flexibility—in this case, used to define both a source and destination SGT, matching SDA’s desired logic of allowing a subset of source/destination SGTs in the SDA fabric.

## DNA Center as a Network Management Platform
Cisco Prime Infrastructure (PI) as an example of a traditional enterprise network management product:
- Single-pane-of-glass: Provides one GUI from which to launch all PI functions and features
- Discovery, inventory, and topology: Discovers network devices, builds an inventory, and arranges them in a topology map
- Entire enterprise: Provides support for traditional enterprise LAN, WAN, and data center management functions
- Methods and protocols: Uses SNMP, SSH, and Telnet, as well as CDP and LLDP, to discover and learn information about the devices in the network
- Lifecycle management: Supports different tasks to install a new device (day 0), configure it to be working in production (day 1), and perform ongoing monitoring and make changes (day n)
- Application visibility: Simplifies QoS configuration deployment to each device 
- Converged wired and wireless: Enables you to manage both the wired and wireless LAN
from the same management platform
- Software Image Management (SWIM): Manages software images on network devices and automates updates
- Plug-and-Play: Performs initial installation tasks for new network devices after you physically install the new device, connect a network cable, and power on

PI itself runs as an application on a server platform with GUI access via a web browser.

### DNA Center Similarities to Traditional Management
DNA Center has all the features listed above as traditional management features. For instance, both can discover network devices and create a network topology map.

Both PI and DNA Center can perform a discover process to find all the devices in the network and then build topology maps to show the devices. (Interestingly, DNA Center can work with PI, using the data discovered by PI rather than performing the discovery work again.)

### DNA Center Differences with Traditional Management
Cisco DNA Center supports SDA, whereas other management apps do not. At the same time, given its long history, as of the time this chapter was written, Cisco PI still had some traditional management features not found in Cisco DNA Center. So think of PI as comprehensive to traditional device management, with Cisco DNA Center having many of those features, while focusing on future features like SDA support.

Cisco DNA Center features help make initial installation easier, simplify the work to implement features that traditionally have challenging configuration, and use tools to help you notice issues more quickly. Some of the features unique to Cisco DNA Center include 
- EasyQoS: Deploys QoS, one of the most complicated features to configure manually, with just a few simple choices from Cisco DNA Center
- Encrypted traffic analysis: Enables Cisco DNA to use algorithms to recognize security threats even in encrypted traffic
- Device 360 and Client 360: Gives a comprehensive (360-degree) view of the health of the device
- Network time travel: Shows past client performance in a timeline for comparison to current behavior
- Path trace: Discovers the actual path packets would take from source to destination based on current forwarding tables

The path trace feature goes much further. The DNA user (from the GUI or the API) specifies a source and destination host and optionally transport protocol and ports. Then the path trace feature shows a map of the path through the network and shows which ACLs are in the path, and whether they would permit or deny the packet.

All of Cisco Digital Network Architecture sets about to help customers reach some big goals: reduced costs, reduced risks, better security and compliance, faster deployment of services through automation and simplified processes, and the list goes on. Cisco DNA Center plays an important role, with all the functions available through its robust northound API, and with its intent-based networking approach for SDA. 